import io
import unicodedata
from pathlib import Path

import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots


# ----------------------------
# Page & Fonts
# ----------------------------
st.set_page_config(
    page_title="ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬",
    page_icon="ğŸŒ±",
    layout="wide",
)

st.markdown(
    """
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap');
html, body, [class*="css"] {
    font-family: 'Noto Sans KR', 'Malgun Gothic', 'Apple SD Gothic Neo', sans-serif;
}
</style>
""",
    unsafe_allow_html=True,
)

PLOTLY_FONT = dict(family="Malgun Gothic, Apple SD Gothic Neo, sans-serif")


# ----------------------------
# Helpers: Unicode-safe file finding
# ----------------------------
def _norm(s: str, form: str) -> str:
    return unicodedata.normalize(form, s)


def _norm_both(s: str) -> set:
    # Compare both NFC and NFD to avoid macOS/Windows normalization issues
    return {_norm(s, "NFC"), _norm(s, "NFD")}


def find_file_unicode_safe(
    data_dir: Path,
    preferred_names: list[str],
    suffixes: tuple[str, ...] = (".xlsx", ".csv"),
    must_contain_keywords: list[str] | None = None,
) -> Path | None:
    """
    Scan data_dir using Path.iterdir() and match filenames using NFC/NFD normalization.
    - preferred_names: exact preferred filename candidates
    - must_contain_keywords: fallback match if preferred not found; all keywords must be in name
    """
    if not data_dir.exists() or not data_dir.is_dir():
        return None

    preferred_norm_sets = [_norm_both(name) for name in preferred_names]
    keywords = must_contain_keywords or []

    # 1) exact match by preferred names (unicode-safe)
    for p in data_dir.iterdir():
        if not p.is_file():
            continue
        if p.suffix.lower() not in [s.lower() for s in suffixes]:
            continue
        p_name_set = _norm_both(p.name)
        for target_set in preferred_norm_sets:
            if p_name_set & target_set:
                return p

    # 2) fallback: keyword match (unicode-safe)
    kw_sets = [_norm_both(k) for k in keywords]  # each keyword in both forms
    for p in data_dir.iterdir():
        if not p.is_file():
            continue
        if p.suffix.lower() not in [s.lower() for s in suffixes]:
            continue
        p_name_nfc = _norm(p.name, "NFC")
        p_name_nfd = _norm(p.name, "NFD")

        ok = True
        for kset in kw_sets:
            # keyword exists in either NFC or NFD representation
            if not any(k in p_name_nfc for k in kset) and not any(k in p_name_nfd for k in kset):
                ok = False
                break
        if ok:
            return p

    return None


def list_data_files(data_dir: Path) -> list[str]:
    if not data_dir.exists():
        return []
    out = []
    for p in data_dir.iterdir():
        if p.is_file():
            out.append(p.name)
    return sorted(out)


# ----------------------------
# Data Loading
# ----------------------------
@st.cache_data(show_spinner=False)
def load_environment_csvs(data_dir: Path) -> dict[str, pd.DataFrame]:
    """
    Load all *_í™˜ê²½ë°ì´í„°.csv files from data_dir.
    Returns dict: {school_name: df}
    Columns expected: time, temperature, humidity, ph, ec
    """
    env = {}
    if not data_dir.exists():
        return env

    for p in data_dir.iterdir():
        if not p.is_file():
            continue
        if p.suffix.lower() != ".csv":
            continue

        # Unicode-safe check for 'í™˜ê²½ë°ì´í„°' in filename
        name_nfc = _norm(p.name, "NFC")
        name_nfd = _norm(p.name, "NFD")
        if ("í™˜ê²½ë°ì´í„°" not in name_nfc) and ("í™˜ê²½ë°ì´í„°" not in name_nfd):
            continue

        try:
            df = pd.read_csv(p)
        except Exception:
            # try encoding fallback
            try:
                df = pd.read_csv(p, encoding="cp949")
            except Exception:
                continue

        # derive school name from filename: "{í•™êµ}_í™˜ê²½ë°ì´í„°.csv"
        # avoid f-string path building; only parse the stem
        stem_nfc = _norm(p.stem, "NFC")
        stem_nfd = _norm(p.stem, "NFD")

        # handle both forms: split by "_í™˜ê²½ë°ì´í„°"
        school = None
        for stem in [stem_nfc, stem_nfd]:
            if "_í™˜ê²½ë°ì´í„°" in stem:
                school = stem.split("_í™˜ê²½ë°ì´í„°")[0].strip()
                break
            if "í™˜ê²½ë°ì´í„°" in stem:
                school = stem.split("í™˜ê²½ë°ì´í„°")[0].replace("_", "").strip()
                break

        if not school:
            continue

        # normalize columns
        rename_map = {}
        for c in df.columns:
            lc = str(c).strip().lower()
            if lc in ["temp", "temperature"]:
                rename_map[c] = "temperature"
            elif lc in ["humid", "humidity"]:
                rename_map[c] = "humidity"
            elif lc in ["ph"]:
                rename_map[c] = "ph"
            elif lc in ["ec"]:
                rename_map[c] = "ec"
            elif lc in ["time", "timestamp", "datetime", "date"]:
                rename_map[c] = "time"
        df = df.rename(columns=rename_map)

        # ensure required columns exist
        for col in ["time", "temperature", "humidity", "ph", "ec"]:
            if col not in df.columns:
                # keep loading but dashboard will warn later
                pass

        # parse time if exists
        if "time" in df.columns:
            df["time"] = pd.to_datetime(df["time"], errors="coerce")

        # numeric convert
        for col in ["temperature", "humidity", "ph", "ec"]:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")

        env[school] = df

    return env


@st.cache_data(show_spinner=False)
def load_growth_xlsx(data_dir: Path) -> tuple[Path | None, dict[str, pd.DataFrame]]:
    """
    Find and load the growth results XLSX (all sheets).
    Return: (xlsx_path, {sheet_name: df})
    Columns expected:
    ê°œì²´ë²ˆí˜¸, ì ìˆ˜(ì¥), ì§€ìƒë¶€ ê¸¸ì´(mm), ì§€í•˜ë¶€ê¸¸ì´(mm), ìƒì¤‘ëŸ‰(g)
    """
    preferred = [
        "4ê°œêµ_ìƒìœ¡ê²°ê³¼ë°ì´í„°.xlsx",
        "4ê°œêµ ìƒìœ¡ê²°ê³¼ë°ì´í„°.xlsx",
        "4ê°œêµ_ìƒìœ¡ ê²°ê³¼ ë°ì´í„°.xlsx",
        "4ê°œêµ ìƒìœ¡ ê²°ê³¼ ë°ì´í„°.xlsx",
    ]

    xlsx_path = find_file_unicode_safe(
        data_dir=data_dir,
        preferred_names=preferred,
        suffixes=(".xlsx",),
        must_contain_keywords=["ìƒìœ¡"],  # fallback: any .xlsx containing 'ìƒìœ¡'
    )

    if xlsx_path is None:
        return None, {}

    try:
        sheets = pd.read_excel(xlsx_path, sheet_name=None, engine="openpyxl")
    except Exception:
        return xlsx_path, {}

    # normalize columns per sheet
    out = {}
    for sheet_name, df in sheets.items():
        if df is None or df.empty:
            continue

        # trim columns
        df.columns = [str(c).strip() for c in df.columns]

        # numeric conversions where possible
        for col in df.columns:
            if col == "ê°œì²´ë²ˆí˜¸":
                df[col] = pd.to_numeric(df[col], errors="coerce")
            if "ìƒì¤‘ëŸ‰" in col or "ì" in col or "ê¸¸ì´" in col:
                df[col] = pd.to_numeric(df[col], errors="coerce")

        out[str(sheet_name).strip()] = df

    return xlsx_path, out


def make_school_meta(env_map: dict[str, pd.DataFrame], growth_sheets: dict[str, pd.DataFrame]) -> pd.DataFrame:
    """
    Create a unified school metadata table without hardcoding sheet names.
    School list = union of env_map keys and growth sheet names (normalized compare).
    """
    # normalize names to match env school & sheet names loosely
    env_keys = list(env_map.keys())
    sheet_keys = list(growth_sheets.keys())

    def canonical(name: str) -> str:
        # remove spaces and normalize
        return _norm(name.replace(" ", ""), "NFC")

    env_can = {canonical(k): k for k in env_keys}
    sheet_can = {canonical(k): k for k in sheet_keys}

    all_can = sorted(set(env_can.keys()) | set(sheet_can.keys()))

    rows = []
    # EC targets given by the prompt (these are experimental conditions, not filenames)
    # This is not sheet-name hardcoding; it's research design metadata.
    ec_target_by_school_hint = {
        "ì†¡ë„ê³ ": 1.0,
        "í•˜ëŠ˜ê³ ": 2.0,
        "ì•„ë¼ê³ ": 4.0,
        "ë™ì‚°ê³ ": 8.0,
    }

    # color hint for UI
    color_hint = {
        "ì†¡ë„ê³ ": "#3b82f6",
        "í•˜ëŠ˜ê³ ": "#22c55e",
        "ì•„ë¼ê³ ": "#f59e0b",
        "ë™ì‚°ê³ ": "#ef4444",
    }

    for can in all_can:
        school_display = env_can.get(can) or sheet_can.get(can) or can
        growth_df = growth_sheets.get(sheet_can.get(can, ""), pd.DataFrame())
        n = int(growth_df.shape[0]) if not growth_df.empty else 0

        # pick EC target if matches known schools; else unknown
        # match by containing substring (unicode-safe)
        target = None
        for k, v in ec_target_by_school_hint.items():
            if k in school_display:
                target = v
                break

        col = None
        for k, v in color_hint.items():
            if k in school_display:
                col = v
                break

        rows.append(
            {
                "í•™êµëª…": school_display,
                "EC ëª©í‘œ": target,
                "ê°œì²´ìˆ˜": n,
                "ìƒ‰ìƒ": col,
            }
        )

    return pd.DataFrame(rows)


def safe_mean(df: pd.DataFrame, col: str) -> float | None:
    if df is None or df.empty or col not in df.columns:
        return None
    v = pd.to_numeric(df[col], errors="coerce").dropna()
    if len(v) == 0:
        return None
    return float(v.mean())


def style_plotly(fig: go.Figure) -> go.Figure:
    fig.update_layout(font=PLOTLY_FONT)
    return fig


# ----------------------------
# App Title
# ----------------------------
st.title("ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬")


# ----------------------------
# Load Data
# ----------------------------
data_dir = Path(__file__).parent / "data"

with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
    env_map = load_environment_csvs(data_dir)
    growth_xlsx_path, growth_sheets = load_growth_xlsx(data_dir)

if len(env_map) == 0:
    st.error("í™˜ê²½ ë°ì´í„°(CSV)ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. data/ í´ë”ì— '*_í™˜ê²½ë°ì´í„°.csv' íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.write("í˜„ì¬ data/ í´ë” íŒŒì¼ ëª©ë¡:")
    st.code("\n".join(list_data_files(data_dir)) or "(ì—†ìŒ)")
    st.stop()

if growth_xlsx_path is None or len(growth_sheets) == 0:
    st.error("ìƒìœ¡ ê²°ê³¼ ë°ì´í„°(XLSX)ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. data/ í´ë”ì— 'ìƒìœ¡'ì´ í¬í•¨ëœ .xlsx íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.write("í˜„ì¬ data/ í´ë” íŒŒì¼ ëª©ë¡:")
    st.code("\n".join(list_data_files(data_dir)) or "(ì—†ìŒ)")
    st.stop()

school_meta = make_school_meta(env_map, growth_sheets)

# Sidebar school filter
schools_all = ["ì „ì²´"] + sorted(school_meta["í•™êµëª…"].dropna().unique().tolist())
selected_school = st.sidebar.selectbox("í•™êµ ì„ íƒ", schools_all, index=0)


def filter_schools(keys: list[str]) -> list[str]:
    if selected_school == "ì „ì²´":
        return keys
    # unicode-safe contain match
    sel_nfc = _norm(selected_school.replace(" ", ""), "NFC")
    out = []
    for k in keys:
        k_nfc = _norm(str(k).replace(" ", ""), "NFC")
        if sel_nfc == k_nfc:
            out.append(k)
    return out


env_keys_filtered = filter_schools(list(env_map.keys()))
sheet_keys_filtered = filter_schools(list(growth_sheets.keys()))

# ----------------------------
# Pre-compute summary stats
# ----------------------------
# total individuals
total_n = int(sum(int(growth_sheets[s].shape[0]) for s in sheet_keys_filtered if s in growth_sheets))

# overall env means across selected schools
temps = []
humids = []
for s in env_keys_filtered:
    df = env_map.get(s, pd.DataFrame())
    if "temperature" in df.columns:
        temps.append(pd.to_numeric(df["temperature"], errors="coerce"))
    if "humidity" in df.columns:
        humids.append(pd.to_numeric(df["humidity"], errors="coerce"))

avg_temp = float(pd.concat(temps).dropna().mean()) if len(temps) else None
avg_humid = float(pd.concat(humids).dropna().mean()) if len(humids) else None

# Best EC by mean fresh weight across sheets (if school EC ëª©í‘œ known)
growth_summary_rows = []
for _, r in school_meta.iterrows():
    school = r["í•™êµëª…"]
    ec_target = r["EC ëª©í‘œ"]
    if school not in sheet_keys_filtered:
        continue
    gdf = growth_sheets.get(school, pd.DataFrame())
    # find weight column
    weight_col = None
    for c in gdf.columns:
        if "ìƒì¤‘ëŸ‰" in str(c):
            weight_col = c
            break
    if weight_col is None:
        continue
    mean_w = safe_mean(gdf, weight_col)
    growth_summary_rows.append({"í•™êµëª…": school, "EC": ec_target, "í‰ê·  ìƒì¤‘ëŸ‰(g)": mean_w, "ê°œì²´ìˆ˜": int(gdf.shape[0])})

growth_summary = pd.DataFrame(growth_summary_rows)

best_ec = None
if not growth_summary.empty and growth_summary["í‰ê·  ìƒì¤‘ëŸ‰(g)"].notna().any():
    best_row = growth_summary.sort_values("í‰ê·  ìƒì¤‘ëŸ‰(g)", ascending=False).iloc[0]
    best_ec = best_row["EC"]

# ----------------------------
# Tabs
# ----------------------------
tab1, tab2, tab3 = st.tabs(["ğŸ“– ì‹¤í—˜ ê°œìš”", "ğŸŒ¡ï¸ í™˜ê²½ ë°ì´í„°", "ğŸ“Š ìƒìœ¡ ê²°ê³¼"])

# =========================================================
# Tab 1: Overview
# =========================================================
with tab1:
    st.subheader("ì—°êµ¬ ë°°ê²½ ë° ëª©ì ")
    st.write(
        """
ê·¹ì§€ì‹ë¬¼ì€ ì•¼ì™¸ ê·¹ì§€ í™˜ê²½ì´ ì•„ë‹ˆë¼ **ê·¹ì§€ì—°êµ¬ì†Œ ìŠ¤ë§ˆíŠ¸íŒœ(í†µì œëœ ì¬ë°° í™˜ê²½)**ì—ì„œ ì¬ë°°ë˜ëŠ” ì‹ë¬¼ì„ ì˜ë¯¸í•œë‹¤.  
ìŠ¤ë§ˆíŠ¸íŒœì—ì„œëŠ” **EC ë†ë„, ì˜¨ë„, ìŠµë„**ì™€ ê°™ì€ í™˜ê²½ ìš”ì¸ì„ ì •ë°€í•˜ê²Œ ì œì–´í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ì‹ë¬¼ì´ ê°€ì¥ ì˜ ìë¼ëŠ” **ìµœì  ì¡°ê±´ì„ ì°¾ëŠ” ê²ƒ**ì´ ë§¤ìš° ì¤‘ìš”í•˜ë‹¤.  
ë³¸ ëŒ€ì‹œë³´ë“œëŠ” 4ê°œ í•™êµì˜ ì‹¤í—˜ ë°ì´í„°ë¥¼ ë¹„êµÂ·ë¶„ì„í•˜ì—¬ **ECë§Œ ê³ ë ¤í–ˆì„ ë•Œ vs ì˜¨Â·ìŠµë„ê¹Œì§€ ê³ ë ¤í–ˆì„ ë•Œ** ìµœì  ì¡°ê±´ì´ ë‹¬ë¼ì§€ëŠ”ì§€ í™•ì¸í•˜ê³ , ìµœì  ECë¥¼ ë„ì¶œí•˜ëŠ” ë° ë„ì›€ì„ ì¤€ë‹¤.
"""
    )

    st.subheader("í•™êµë³„ EC ì¡°ê±´")
    show_meta = school_meta.copy()
    if selected_school != "ì „ì²´":
        show_meta = show_meta[show_meta["í•™êµëª…"] == selected_school]

    st.dataframe(show_meta, use_container_width=True)

    st.subheader("ì£¼ìš” ì§€í‘œ")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì´ ê°œì²´ìˆ˜", f"{total_n:,d}")
    c2.metric("í‰ê·  ì˜¨ë„", "-" if avg_temp is None else f"{avg_temp:.2f} Â°C")
    c3.metric("í‰ê·  ìŠµë„", "-" if avg_humid is None else f"{avg_humid:.2f} %")
    c4.metric("ìµœì  EC(í‰ê·  ìƒì¤‘ëŸ‰ ê¸°ì¤€)", "-" if best_ec is None else f"{best_ec}")

# =========================================================
# Tab 2: Environment Data
# =========================================================
with tab2:
    st.subheader("í•™êµë³„ í™˜ê²½ í‰ê·  ë¹„êµ")

    # compute averages per school
    env_rows = []
    for s in env_keys_filtered:
        d = env_map.get(s, pd.DataFrame())
        env_rows.append(
            {
                "í•™êµ": s,
                "í‰ê·  ì˜¨ë„(Â°C)": safe_mean(d, "temperature"),
                "í‰ê·  ìŠµë„(%)": safe_mean(d, "humidity"),
                "í‰ê·  pH": safe_mean(d, "ph"),
                "í‰ê·  EC(ì‹¤ì¸¡)": safe_mean(d, "ec"),
            }
        )
    env_avg = pd.DataFrame(env_rows)

    # add EC target from meta if available
    env_avg = env_avg.merge(school_meta[["í•™êµëª…", "EC ëª©í‘œ"]], left_on="í•™êµ", right_on="í•™êµëª…", how="left").drop(
        columns=["í•™êµëª…"]
    )

    fig = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=("Avg Temperature", "Avg Humidity", "Avg pH", "Target EC vs Measured EC"),
    )

    # bar: temp
    fig.add_trace(
        go.Bar(x=env_avg["í•™êµ"], y=env_avg["í‰ê·  ì˜¨ë„(Â°C)"], name="Avg Temp"),
        row=1,
        col=1,
    )

    # bar: humid
    fig.add_trace(
        go.Bar(x=env_avg["í•™êµ"], y=env_avg["í‰ê·  ìŠµë„(%)"], name="Avg Humidity"),
        row=1,
        col=2,
    )

    # bar: pH
    fig.add_trace(
        go.Bar(x=env_avg["í•™êµ"], y=env_avg["í‰ê·  pH"], name="Avg pH"),
        row=2,
        col=1,
    )

    # dual bar: target vs measured ec
    fig.add_trace(
        go.Bar(x=env_avg["í•™êµ"], y=env_avg["EC ëª©í‘œ"], name="Target EC"),
        row=2,
        col=2,
    )
    fig.add_trace(
        go.Bar(x=env_avg["í•™êµ"], y=env_avg["í‰ê·  EC(ì‹¤ì¸¡)"], name="Measured EC"),
        row=2,
        col=2,
    )

    fig.update_layout(
        barmode="group",
        height=700,
        title_text="Environment Averages (by School)",
        font=PLOTLY_FONT,
        legend=dict(orientation="h", yanchor="bottom", y=1.05, xanchor="left", x=0),
    )
    st.plotly_chart(fig, use_container_width=True)

    st.divider()
    st.subheader("ì„ íƒí•œ í•™êµ ì‹œê³„ì—´")

    # show time series for selected school (if 'ì „ì²´' show first school)
    ts_school = selected_school
    if ts_school == "ì „ì²´":
        ts_school = env_keys_filtered[0] if env_keys_filtered else None

    if ts_school is None or ts_school not in env_map:
        st.error("ì‹œê³„ì—´ì„ í‘œì‹œí•  í•™êµë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        d = env_map[ts_school].copy()
        if "time" not in d.columns or d["time"].isna().all():
            st.error("ì‹œê°„(time) ì»¬ëŸ¼ì„ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CSVì˜ 'time' ì»¬ëŸ¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            # target EC if exists
            target_ec = None
            m = school_meta[school_meta["í•™êµëª…"] == ts_school]
            if not m.empty:
                target_ec = m.iloc[0]["EC ëª©í‘œ"]

            # Temperature
            if "temperature" in d.columns:
                fig_t = px.line(d.sort_values("time"), x="time", y="temperature", title="Temperature Over Time")
                fig_t.update_layout(font=PLOTLY_FONT)
                st.plotly_chart(fig_t, use_container_width=True)

            # Humidity
            if "humidity" in d.columns:
                fig_h = px.line(d.sort_values("time"), x="time", y="humidity", title="Humidity Over Time")
                fig_h.update_layout(font=PLOTLY_FONT)
                st.plotly_chart(fig_h, use_container_width=True)

            # EC with target line
            if "ec" in d.columns:
                fig_e = px.line(d.sort_values("time"), x="time", y="ec", title="EC Over Time")
                if target_ec is not None and pd.notna(target_ec):
                    fig_e.add_hline(y=float(target_ec), line_dash="dash", annotation_text="Target EC")
                fig_e.update_layout(font=PLOTLY_FONT)
                st.plotly_chart(fig_e, use_container_width=True)

    with st.expander("í™˜ê²½ ë°ì´í„° ì›ë³¸ ë³´ê¸° ë° ë‹¤ìš´ë¡œë“œ"):
        # show combined table for selected scope
        frames = []
        for s in env_keys_filtered:
            tmp = env_map[s].copy()
            tmp.insert(0, "School", s)
            frames.append(tmp)
        env_all = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()

        st.dataframe(env_all, use_container_width=True)

        # download CSV
        csv_bytes = env_all.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            label="í™˜ê²½ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_bytes,
            file_name="í™˜ê²½ë°ì´í„°_í†µí•©.csv",
            mime="text/csv",
        )

# =========================================================
# Tab 3: Growth Results
# =========================================================
with tab3:
    st.subheader("ğŸ¥‡ í•µì‹¬ ê²°ê³¼: ECë³„ í‰ê·  ìƒì¤‘ëŸ‰")

    if growth_summary.empty:
        st.error("ìƒì¤‘ëŸ‰ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ ìƒìœ¡ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
    else:
        # Highlight best EC
        if best_ec is not None:
            st.info(f"í˜„ì¬ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ í‰ê·  ìƒì¤‘ëŸ‰ì´ ê°€ì¥ ë†’ì€ ì¡°ê±´ì€ **EC {best_ec}** ì…ë‹ˆë‹¤. (í•™êµ ë‹¨ìœ„ ë¹„êµ)")

        # card-like metrics per EC
        cols = st.columns(min(4, len(growth_summary)))
        sorted_sum = growth_summary.sort_values("í‰ê·  ìƒì¤‘ëŸ‰(g)", ascending=False)
        for i, (_, r) in enumerate(sorted_sum.iterrows()):
            if i >= len(cols):
                break
            label = f"{r['í•™êµëª…']} (EC {r['EC']})"
            value = "-" if pd.isna(r["í‰ê·  ìƒì¤‘ëŸ‰(g)"]) else f"{r['í‰ê·  ìƒì¤‘ëŸ‰(g)']:.2f} g"
            cols[i].metric(label, value)

    st.divider()
    st.subheader("ECë³„ ìƒìœ¡ ë¹„êµ (2x2)")

    # build bar charts for: mean weight, mean leaves, mean shoot length, count
    rows = []
    for s in sheet_keys_filtered:
        gdf = growth_sheets.get(s, pd.DataFrame())
        if gdf.empty:
            continue

        # detect columns
        weight_col = next((c for c in gdf.columns if "ìƒì¤‘ëŸ‰" in str(c)), None)
        leaf_col = next((c for c in gdf.columns if "ì" in str(c)), None)
        shoot_col = next((c for c in gdf.columns if "ì§€ìƒë¶€" in str(c)), None)

        # EC target
        ec_target = None
        m = school_meta[school_meta["í•™êµëª…"] == s]
        if not m.empty:
            ec_target = m.iloc[0]["EC ëª©í‘œ"]

        rows.append(
            {
                "í•™êµ": s,
                "EC": ec_target,
                "í‰ê·  ìƒì¤‘ëŸ‰(g)": safe_mean(gdf, weight_col) if weight_col else None,
                "í‰ê·  ì ìˆ˜": safe_mean(gdf, leaf_col) if leaf_col else None,
                "í‰ê·  ì§€ìƒë¶€ ê¸¸ì´(mm)": safe_mean(gdf, shoot_col) if shoot_col else None,
                "ê°œì²´ìˆ˜": int(gdf.shape[0]),
            }
        )

    growth_avg = pd.DataFrame(rows)

    fig2 = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=("Mean Fresh Weight (g)", "Mean Leaf Count", "Mean Shoot Length (mm)", "Sample Size (n)"),
    )

    fig2.add_trace(go.Bar(x=growth_avg["í•™êµ"], y=growth_avg["í‰ê·  ìƒì¤‘ëŸ‰(g)"], name="Fresh Weight"), row=1, col=1)
    fig2.add_trace(go.Bar(x=growth_avg["í•™êµ"], y=growth_avg["í‰ê·  ì ìˆ˜"], name="Leaf Count"), row=1, col=2)
    fig2.add_trace(go.Bar(x=growth_avg["í•™êµ"], y=growth_avg["í‰ê·  ì§€ìƒë¶€ ê¸¸ì´(mm)"], name="Shoot Length"), row=2, col=1)
    fig2.add_trace(go.Bar(x=growth_avg["í•™êµ"], y=growth_avg["ê°œì²´ìˆ˜"], name="n"), row=2, col=2)

    fig2.update_layout(
        height=700,
        title_text="Growth Comparison (by School / EC Condition)",
        font=PLOTLY_FONT,
        showlegend=False,
    )
    st.plotly_chart(fig2, use_container_width=True)

    st.divider()
    st.subheader("í•™êµë³„ ìƒì¤‘ëŸ‰ ë¶„í¬")

    # build long-form for distribution plots
    long_rows = []
    for s in sheet_keys_filtered:
        gdf = growth_sheets.get(s, pd.DataFrame())
        if gdf.empty:
            continue
        weight_col = next((c for c in gdf.columns if "ìƒì¤‘ëŸ‰" in str(c)), None)
        if not weight_col:
            continue
        tmp = gdf[[weight_col]].copy()
        tmp["í•™êµ"] = s
        tmp = tmp.rename(columns={weight_col: "ìƒì¤‘ëŸ‰(g)"})
        long_rows.append(tmp)

    if long_rows:
        long_df = pd.concat(long_rows, ignore_index=True)
        fig_box = px.box(long_df, x="í•™êµ", y="ìƒì¤‘ëŸ‰(g)", points="all", title="Fresh Weight Distribution by School")
        fig_box.update_layout(font=PLOTLY_FONT)
        st.plotly_chart(fig_box, use_container_width=True)
    else:
        st.error("ë¶„í¬ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ìƒì¤‘ëŸ‰ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    st.divider()
    st.subheader("ìƒê´€ê´€ê³„ ë¶„ì„ (ì‚°ì ë„ 2ê°œ)")

    # Combine for scatter: Leaf vs Weight, Shoot vs Weight
    scatter_rows = []
    for s in sheet_keys_filtered:
        gdf = growth_sheets.get(s, pd.DataFrame())
        if gdf.empty:
            continue

        weight_col = next((c for c in gdf.columns if "ìƒì¤‘ëŸ‰" in str(c)), None)
        leaf_col = next((c for c in gdf.columns if "ì" in str(c)), None)
        shoot_col = next((c for c in gdf.columns if "ì§€ìƒë¶€" in str(c)), None)
        if not weight_col:
            continue

        cols_needed = [c for c in [leaf_col, shoot_col, weight_col] if c is not None]
        tmp = gdf[cols_needed].copy()
        tmp["í•™êµ"] = s
        tmp = tmp.rename(
            columns={
                weight_col: "ìƒì¤‘ëŸ‰(g)",
                leaf_col: "ì ìˆ˜(ì¥)" if leaf_col else leaf_col,
                shoot_col: "ì§€ìƒë¶€ ê¸¸ì´(mm)" if shoot_col else shoot_col,
            }
        )
        scatter_rows.append(tmp)

    if scatter_rows:
        scat = pd.concat(scatter_rows, ignore_index=True)

        c1, c2 = st.columns(2)
        with c1:
            if "ì ìˆ˜(ì¥)" in scat.columns:
                fig_sc1 = px.scatter(scat, x="ì ìˆ˜(ì¥)", y="ìƒì¤‘ëŸ‰(g)", color="í•™êµ", title="Leaf Count vs Fresh Weight")
                fig_sc1.update_layout(font=PLOTLY_FONT)
                st.plotly_chart(fig_sc1, use_container_width=True)
            else:
                st.error("ì ìˆ˜ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        with c2:
            if "ì§€ìƒë¶€ ê¸¸ì´(mm)" in scat.columns:
                fig_sc2 = px.scatter(scat, x="ì§€ìƒë¶€ ê¸¸ì´(mm)", y="ìƒì¤‘ëŸ‰(g)", color="í•™êµ", title="Shoot Length vs Fresh Weight")
                fig_sc2.update_layout(font=PLOTLY_FONT)
                st.plotly_chart(fig_sc2, use_container_width=True)
            else:
                st.error("ì§€ìƒë¶€ ê¸¸ì´ ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        st.error("ìƒê´€ê´€ê³„ ì‚°ì ë„ë¥¼ ë§Œë“¤ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

    with st.expander("í•™êµë³„ ìƒìœ¡ ë°ì´í„° ì›ë³¸ ë³´ê¸° ë° ë‹¤ìš´ë¡œë“œ"):
        # show selected sheets
        for s in sheet_keys_filtered:
            st.markdown(f"**{s}**")
            st.dataframe(growth_sheets[s], use_container_width=True)

        # download XLSX (all selected sheets)
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
            for s in sheet_keys_filtered:
                growth_sheets[s].to_excel(writer, index=False, sheet_name=str(s)[:31])
        buffer.seek(0)

        st.download_button(
            label="ìƒìœ¡ ë°ì´í„° XLSX ë‹¤ìš´ë¡œë“œ (ì„ íƒ ë²”ìœ„)",
            data=buffer,
            file_name="ìƒìœ¡ë°ì´í„°_ì„ íƒë²”ìœ„.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
